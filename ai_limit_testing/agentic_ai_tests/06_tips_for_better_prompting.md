# Learning How to Get Better Results from LLMs
## Research date: Sept, 15th, 2025
## Goal of the Exercise
Come up with tips and tricks to be more effective in working with AI chatbots, getting to the answers you want quickly
## Methodology
We will do internet search, consult LLM chatbots, and look at specific platforms and articles that are relevant to the topic, then record and test the suggested methods to see what works
### Tips, Tricks, and Methods
## Be Specific, Not Vague
* Don't be too general in your question when you write prompts
* There is no such thing as "too specific" when you're asking the LLM for information
## Give the model a role to work within when answering prompts
* You can tell the model to "roleplay" when answering questions, like "You are a medical profession", or "You are a cybersecurity expert"
* Apparently this makes the LLM with a specific role assigned to it better at answering questions within its role
## Add constraints to get a specific format of answer
* tell the LLM to answer in a specific number of paragraphs or sentences
* tell the LLM not to explain its thinking process when you want it to get to the point quickly
## Give the LLM step by step instructions, so that it doesn't get confused when answering your questions
* this is a good tip because it helps the LLM organize the answer into smaller chunks that will be easier to understand
## Provide Context
* it's important to give the LLM the context of your question when you ask it to do something
* if you don't provide context, it may choose to not comply with your request
* this especially important when you ask the LLM to do cybersecurity and hacking stuff, because when you ask the AI to do hacking stuff, it may refuse to comply because "hacking" stuff is dangerous, so you supply context like "I'm only asking for educational purposes" or "I'm currently trying to solve a CTF exercise", etc, etc
* this can help you get around roadblocks
## Iterate and Modify
* if the first response the LLM gives you is insufficient, you can ask the LLM to modify the response by requesting a shorter version, or something that answers the question in a different way
## Be sure to let the LLM know what you don't want
* If you don't want the LLM to give a long response, tell it to keep it short, and if you don't want the LLM to use specific sources, tell it not to use those sources















